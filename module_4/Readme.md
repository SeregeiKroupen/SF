# Project #4 "Computer says: "No!"   
**Data Science Specialization course by SkillFactory**
_____
Second edition ("credit_scoring_v2")

I made second edition of project 4, as my first time was not successful. I return to 
it after finishing study of DS in SkillFactory. So I used more knowledge to achive better result.

It was not difficult and long. I used CatBoostClassifier and TargetEncoder as base of model.
And most useful thing was balancing of classes. Initially we had near 7:1 ballance between 
"non-default" and "default" classes, and I made balance near 4:3.  

Score on liderboard is 35.032% (F1 of default calss)

____
Первая версия (в рамках курса)   
Тут представлена моя работа по проекту 4 кредитного скоринга "Копьютер говорит "нет".

Хочется сказать, присказкой про неудачную торговлю: "Продавали - веселились, посчитали - прослезились". Пока я вел работу по EDA и FE, у меня создавалось впечатление, что я освоил таки тему. Если и были сомнения - то их не осталось: я дата-саентист. Но оказалось, что рано я радовался...

Нет, отрицать, что мне многое удалось, и что я многому научился - нельзя. 
1. Я все таки доволен тем, как мне удалось составить модель с отличным результатом на валидации. 
2. Я очень доволен, что попробовал, как хотел еще одну модель, кроме логистрической регресси (хотя, конечно, я хотел больше моделей попробовать). 
3. Я невероятно доволен, что попробовал подбирать гиперпараметры с помощью не только сетки, но и рандомного поиска. И что меня сильнее всего впечатлило - применение этих параметров на "Случайном Лесе" еще сильнее подняло целевую метрику.
4. Я доволен, что смог осуществить идею сбора даных по этам работы с датасетом. 
5. Когда я внезапно узнал, что целевая метрика, это еще не все, и что нужно использовать другие метрики. Проверив их, обнаружилось, что модель никак не предсказывала дефолты, то есть она была сильно разбалансирована по классам. Хотя, как казалось - 1:7 это не много. Что ж. Идея "в лоб" увеличить количество записей с дефолтом (фактически я их утриавал) и сокращение записй без дефолта (на 40%) существенно улучшало ситуацию с предсказаниями дефолтов. Но это было уже не важно...

Потому что мой результат - 0,61. А если исключить мой самый "любимый" вектор, то 0,72.

Вердикт не утешителный. Как ни красиво поучился набор векторов, построен он на неподходящей методике. Главный изъян, как полагаю,  - утечка данных. Соблазн, упрекнуть постановку задания есть. Оно не безупречно. Но мои усилия, показать, что хоть какая-то польза от моей работы есть, не увенчалась успехом. Я постарался применить мою схему построения и преобразования датасета, исключив утечку данных. Но успеха эта попытка не принесла. А моделирование, как мне показалось, более реальной ситуации работы скорингового отдела - вообще не предсказала никаих дефолтов, и я уже не имею сил разбираться, что с этим делать. 

Да. И еще была попытка работы в команде. Penny Drops. Эврика не удалась. Теперь ясно только то, что надо как-то двигаться дальше и исправляться в будущем. 
