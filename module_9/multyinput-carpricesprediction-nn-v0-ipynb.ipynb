{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os, re, math\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-05-15T16:44:33.757656Z","iopub.execute_input":"2022-05-15T16:44:33.758313Z","iopub.status.idle":"2022-05-15T16:44:44.484148Z","shell.execute_reply.started":"2022-05-15T16:44:33.758214Z","shell.execute_reply":"2022-05-15T16:44:44.483421Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n\nimport warnings\nfrom sklearn import metrics\n\nfrom catboost import CatBoostRegressor\n\nimport category_encoders as ce\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-05-15T16:44:46.874086Z","iopub.execute_input":"2022-05-15T16:44:46.874788Z","iopub.status.idle":"2022-05-15T16:44:48.268541Z","shell.execute_reply.started":"2022-05-15T16:44:46.87475Z","shell.execute_reply":"2022-05-15T16:44:48.267814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing import sequence\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nimport albumentations","metadata":{"execution":{"iopub.status.busy":"2022-05-15T16:44:49.469323Z","iopub.execute_input":"2022-05-15T16:44:49.469577Z","iopub.status.idle":"2022-05-15T16:44:55.459243Z","shell.execute_reply.started":"2022-05-15T16:44:49.469547Z","shell.execute_reply":"2022-05-15T16:44:55.458509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 15, 10         # make default plot size\n%config InlineBackend.figure_format = 'svg' # make default plot format svg\n%matplotlib inline\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-05-15T16:44:55.460784Z","iopub.execute_input":"2022-05-15T16:44:55.461025Z","iopub.status.idle":"2022-05-15T16:44:55.518211Z","shell.execute_reply.started":"2022-05-15T16:44:55.460991Z","shell.execute_reply":"2022-05-15T16:44:55.517522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data loads","metadata":{}},{"cell_type":"code","source":"# ---- Path for Kaggle ---\nPATH = '../input/sf-dst-car-price-prediction-part2/'\n# ---- Path for local ----\n# PATH=''\n\ndata = pd.read_csv(PATH + 'train.csv')\ntest = pd.read_csv(PATH + 'test.csv')\nsample_submission = pd.read_csv(PATH + 'sample_submission.csv')\npd.set_option('display.max_columns', None)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T16:49:52.153578Z","iopub.execute_input":"2022-05-15T16:49:52.15424Z","iopub.status.idle":"2022-05-15T16:49:52.668739Z","shell.execute_reply.started":"2022-05-15T16:49:52.154199Z","shell.execute_reply":"2022-05-15T16:49:52.668018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED=42\nnp.random.seed(SEED)\nTARGET = 'price'","metadata":{"execution":{"iopub.status.busy":"2022-05-15T16:49:54.023877Z","iopub.execute_input":"2022-05-15T16:49:54.024265Z","iopub.status.idle":"2022-05-15T16:49:54.030441Z","shell.execute_reply.started":"2022-05-15T16:49:54.024232Z","shell.execute_reply":"2022-05-15T16:49:54.029635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Function\nEDA, FE, etc.","metadata":{}},{"cell_type":"code","source":"def find_number(field: str):\n    \"\"\"\n    function to take only first numeric data from string\n    :param field: string to find number\n    :return: number (in string format)\n    \"\"\"\n\n    # mask for search\n    p = '[\\d]+[.,\\d]+|[\\d]*[.][\\d]+|[\\d]+'\n\n    # main cycle for searching\n    if re.search(p, field) is not None:\n        for catch in re.finditer(p, field):\n            return catch[0]","metadata":{"execution":{"iopub.status.busy":"2022-05-15T16:49:55.968112Z","iopub.execute_input":"2022-05-15T16:49:55.968642Z","iopub.status.idle":"2022-05-15T16:49:55.975913Z","shell.execute_reply.started":"2022-05-15T16:49:55.968604Z","shell.execute_reply":"2022-05-15T16:49:55.97515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def name_separate(item):\n    \"\"\"\n    function to separete text value in vector 'name' and return only first part\n    :param item: text value from field of vector\n    :return: first part of text value like '180 BlueEFFICIENCY 1.8 AT'\n    \"\"\"\n    result = item.replace('(','-').replace(')','-').split('-')\n    if len(result)==3:\n        third = result[2]\n    else:\n        third = ''\n\n    return result[0]#, result[1], third","metadata":{"execution":{"iopub.status.busy":"2022-05-15T16:49:56.869615Z","iopub.execute_input":"2022-05-15T16:49:56.869976Z","iopub.status.idle":"2022-05-15T16:49:56.880326Z","shell.execute_reply.started":"2022-05-15T16:49:56.869936Z","shell.execute_reply":"2022-05-15T16:49:56.879378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mape(y_true, y_pred):\n    \"\"\"\n    function to calculate Mean Absolute Percentage Error\n    \"\"\"\n    return np.mean(np.abs((y_pred-y_true)/y_true))*100","metadata":{"execution":{"iopub.status.busy":"2022-05-15T16:49:57.417636Z","iopub.execute_input":"2022-05-15T16:49:57.418116Z","iopub.status.idle":"2022-05-15T16:49:57.421876Z","shell.execute_reply.started":"2022-05-15T16:49:57.418078Z","shell.execute_reply":"2022-05-15T16:49:57.421224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.DataFrame()\ndef feature_imp(dataset, regressor, encoder, test_drop = True, target='price'):\n    \"\"\"\n    function for checking feature importance on ML\n    :param dataset: dataset for ML\n    :param regressor: algorithm of ML\n    :param encoder: encoder for categorical vectors\n    :param test_drop: boolean flag whether need to separate test data from dataset\n    :param target: name of target\n    :return: list of features with weights descending, score of algorithm and MAPE score\n    \"\"\"\n    global results\n\n    # copy dataset useful if you need to drop some vectors from dataset\n    dataset=dataset.copy()\n\n    # checkin boolean flag to drop test data from dataset\n    if test_drop:\n        dataset = dataset[dataset.test == 0]\n\n    # drop vector 'test'\n    # dataset.drop(['test'], axis=1, inplace=True)\n\n    # make variables x and y for ML model\n    x, y = dataset.drop(target, axis=1), np.log(dataset[target])\n\n    # encoding categorical vectors with encoder\n    encoder.fit(x, y)\n    X = encoder.transform(x)\n\n    # split for validate and fit ML model\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=SEED)\n    regressor.fit(X_train, y_train)\n\n    # make dataframe with features importance\n    importance = regressor.feature_importances_\n    value = pd.DataFrame(data=importance, index=X.columns, columns=['importance'])\n    print(value.importance.sort_values(ascending=False))\n\n    # calculate ML model score\n    score = regressor.score(X_test, y_test)\n    print(f'Score of regressor {score*100:0.2f}%')\n\n    # calculate MAPE score\n    predict = np.exp(regressor.predict(X_test))\n    print(f\"MAPE: {(mape(np.exp(y_test), predict)):0.2f}%\")\n\n    if not results.empty:\n        results.drop(columns=results.columns, inplace=True)\n    results = X_test.copy()\n    results['y_test'] = np.exp(y_test)\n    results['predict'] = predict.astype('int64')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T16:49:58.032655Z","iopub.execute_input":"2022-05-15T16:49:58.033358Z","iopub.status.idle":"2022-05-15T16:49:58.045052Z","shell.execute_reply.started":"2022-05-15T16:49:58.033307Z","shell.execute_reply":"2022-05-15T16:49:58.043104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cooking time for data","metadata":{}},{"cell_type":"code","source":"def cooking():\n    global data, test\n\n    # ---- load datasets ---\n    data = pd.read_csv(PATH + 'train.csv')\n    test = pd.read_csv(PATH + 'test.csv')\n    sample_submission = pd.read_csv(PATH + 'sample_submission.csv')\n\n    # --- bodyType ----\n    ## -- repair mistake in data\n    data.loc[(data.bodyType == 'хэтчбек 3 дв.') & (data.numberOfDoors == 2), 'numberOfDoors'] = 3\n\n    ## -- working\n    n_doors = {\n        'внедорожник 3 дв.': 'внедорожник',\n        'внедорожник 5 дв.': 'внедорожник',\n        'внедорожник открытый': 'внедорожник открытый',\n        'кабриолет': 'кабриолет',\n        'компактвэн': 'компактвэн',\n        'купе': 'купе',\n        'купе-хардтоп': \"купе-хардтоп\",\n        'лимузин': 'лимузин',\n        'лифтбек': 'лифтбек',\n        'минивэн': 'минивэн',\n        'пикап двойная кабина': 'пикап двойная кабина',\n        'родстер': 'родстер',\n        'седан': 'седан',\n        'седан 2 дв.': 'седан',\n        'универсал 5 дв.': 'универсал',\n        'хэтчбек 3 дв.': 'хэтчбек',\n        'хэтчбек 5 дв.': 'хэтчбек'\n    } # dic of clear body types\n    data['body'] = data.bodyType.map(n_doors)\n    test['body'] = test.bodyType.map(n_doors)\n    data['bodyDoors'] = data.apply(lambda q: str(q.body) + \" \" + str(q.numberOfDoors), axis=1)\n    test['bodyDoors'] = test.apply(lambda q: str(q.body) + \" \" + str(q.numberOfDoors), axis=1)\n\n    # --- engineDisplacement ---\n    data['engineDisplacementValue'] = data.engineDisplacement.apply(find_number)\n    test['engineDisplacementValue'] = test.engineDisplacement.apply(find_number)\n    data.engineDisplacementValue.fillna(value=0.0001, inplace=True)\n    test.engineDisplacementValue.fillna(value=0.0001, inplace=True)\n    data.engineDisplacementValue = data.engineDisplacementValue.apply(float)\n    test.engineDisplacementValue = test.engineDisplacementValue.apply(float)\n    scaler = MinMaxScaler()\n    data['edvMinMax'] = scaler.fit_transform(data[['engineDisplacementValue']])\n    test['edvMinMax'] = scaler.transform(test[['engineDisplacementValue']])\n    \n    data['displacement']=data.engineDisplacementValue//1\n    test['displacement']=test.engineDisplacementValue//1\n    \n    # --- enginePower ---\n    data['enginePowerValue'] = data.enginePower.apply(find_number).apply(int)\n    test['enginePowerValue'] = test.enginePower.apply(find_number).apply(int)\n\n    data['epvLog'] = data.enginePowerValue.apply(np.log)\n    test['epvLog'] = test.enginePowerValue.apply(np.log)\n\n    \n    # --- productionDate ---\n    # till 3 years - free technical support \n    # till 5 years - guarantee period \n    # after 10 years - vehicle loose up to half cost \n    # after 30 years - it is just rare \n    age = lambda date: 3 if date >= 2018 \\\n        else 5 if date >=2016 else 10 if date >= 2011 \\\n        else 20 if date>=2001 else 30\n\n    data['age']=data.productionDate.apply(age)\n    test['age']=test.productionDate.apply(age)    \n    \n    \n    # --- modelDate ---\n    data['modelDateLog']=data.modelDate.apply(lambda q: np.log(2022-q))\n    test['modelDateLog']=test.modelDate.apply(lambda q: np.log(2022-q))\n    scaler = MinMaxScaler()\n    data['modelDateMM'] = scaler.fit_transform(data[['modelDate']])\n    test['modelDateMM'] = scaler.transform(test[['modelDate']])\n\n    # --- owners ---\n    data['Владельцы'].fillna('2 владельца', inplace=True)\n    data['owners'] = data['Владельцы'].apply(find_number)\n    data['ownerValue'] = data.apply(lambda q: int(q.owners), axis=1)\n    data['Владение'].fillna('Не известно', inplace=True)\n\n    test['Владельцы'].fillna('2 владельца', inplace=True)\n    test['owners']=test['Владельцы'].apply(find_number)\n    test['ownerValue'] = test.apply(lambda q: int(q.owners), axis=1)\n    test['Владение'].fillna('Не известно', inplace=True)\n\n    # --- delete noise data ---\n    ejection={\n        'color': {'розовый'},\n        'engineDisplacement': {'3.4 LTR', '4.6 LTR', '4.9 LTR', '5.6 LTR', '6.3 LTR'},\n        'sell_id': {1100083262},\n        'Руль': {'Правый'},\n        'bodyType': {'седан 2 дв.', 'компактвэн', 'лимузин'}\n    }\n    for vector, values in ejection.items():\n        for value in values:\n            data = data[data[vector] != value]\n\n    # ---name---\n    data['name1'] = data.name.apply(name_separate)\n    data['vehicle'] = data.brand + ' ' + data.model_info + ' ' + data.vehicleConfiguration + ' ' + data.name1\n\n    test['name1'] = test.name.apply(name_separate)\n    test['vehicle'] = test.brand + ' ' + test.model_info + ' ' + test.vehicleConfiguration + ' ' + test.name1\n\n    # --- description ---\n    data['descriptionLen'] = data.description.apply(lambda q: len(q.split()))\n    test['descriptionLen'] = test.description.apply(lambda q: len(q.split()))\n\ncooking()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T16:49:59.474618Z","iopub.execute_input":"2022-05-15T16:49:59.474967Z","iopub.status.idle":"2022-05-15T16:50:00.546667Z","shell.execute_reply.started":"2022-05-15T16:49:59.474932Z","shell.execute_reply":"2022-05-15T16:50:00.545863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(['price', 'description'], axis=1).info()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T16:50:00.56168Z","iopub.execute_input":"2022-05-15T16:50:00.562277Z","iopub.status.idle":"2022-05-15T16:50:00.59895Z","shell.execute_reply.started":"2022-05-15T16:50:00.562242Z","shell.execute_reply":"2022-05-15T16:50:00.598203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-05-15T16:50:05.143081Z","iopub.execute_input":"2022-05-15T16:50:05.143616Z","iopub.status.idle":"2022-05-15T16:50:05.148035Z","shell.execute_reply.started":"2022-05-15T16:50:05.143578Z","shell.execute_reply":"2022-05-15T16:50:05.146675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_to_drop = ['engineDisplacementValue','modelDate','modelDateMM',\n                'Руль',\n                'enginePowerValue',\n                'description',\n                ]\nparameters = {\n    'regressor': CatBoostRegressor(random_state=SEED),\n    'encoder': ce.TargetEncoder()\n}\nfeature_imp(data.drop(list_to_drop, axis=1), test_drop=False, **parameters)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:30:25.165912Z","iopub.execute_input":"2022-05-15T13:30:25.166688Z","iopub.status.idle":"2022-05-15T13:30:29.182442Z","shell.execute_reply.started":"2022-05-15T13:30:25.166646Z","shell.execute_reply":"2022-05-15T13:30:29.181745Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Catboost submission","metadata":{}},{"cell_type":"code","source":"x, y = data.drop([TARGET], axis=1), np.log(data[TARGET])\nq = test","metadata":{"execution":{"iopub.status.busy":"2022-05-07T06:53:37.062187Z","iopub.execute_input":"2022-05-07T06:53:37.062445Z","iopub.status.idle":"2022-05-07T06:53:37.071403Z","shell.execute_reply.started":"2022-05-07T06:53:37.062414Z","shell.execute_reply":"2022-05-07T06:53:37.070549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder=ce.TargetEncoder()\nencoder.fit(x, y)\nx = encoder.transform(x)\nq = encoder.transform(q)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T06:53:38.196212Z","iopub.execute_input":"2022-05-07T06:53:38.196692Z","iopub.status.idle":"2022-05-07T06:53:38.741717Z","shell.execute_reply.started":"2022-05-07T06:53:38.196656Z","shell.execute_reply":"2022-05-07T06:53:38.740963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CatBoostRegressor(iterations = 5000,\n                          random_seed = SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['R2', 'MAE'],\n                          #silent=True,\n                          )\nmodel.fit(x, np.log(y),\n          #cat_features=cat_features_ids,\n          #eval_set=(x, np.log(y_test)),\n          verbose_eval=0,\n          #use_best_model=True,\n          #plot=True\n          )\n\nmodel.save_model('catboost_single_model_EDA1.model')\n\nq['price'] = np.exp(model.predict(q))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T06:53:57.259352Z","iopub.execute_input":"2022-05-07T06:53:57.259626Z","iopub.status.idle":"2022-05-07T06:54:19.51544Z","shell.execute_reply.started":"2022-05-07T06:53:57.259592Z","shell.execute_reply":"2022-05-07T06:54:19.514699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"catboost_prediction = q[['sell_id', 'price']]\ncatboost_prediction.to_csv('catboost_sub.csv', index=False)\ncatboost_prediction\n# 11.6153% on leaderboard","metadata":{"execution":{"iopub.status.busy":"2022-05-04T19:28:18.1981Z","iopub.execute_input":"2022-05-04T19:28:18.19836Z","iopub.status.idle":"2022-05-04T19:28:18.224362Z","shell.execute_reply.started":"2022-05-04T19:28:18.198331Z","shell.execute_reply":"2022-05-04T19:28:18.223603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_to_drop = ['engineDisplacementValue','modelDate','modelDateMM',\n                'Руль',\n                'enginePowerValue',\n                'description',\n                ]\nparameters = {\n    'regressor': CatBoostRegressor(random_state=SEED),\n    'encoder': ce.TargetEncoder()\n}\nfeature_imp(data.drop(list_to_drop, axis=1), test_drop=False, **parameters)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:02:18.98603Z","iopub.execute_input":"2022-05-07T15:02:18.98671Z","iopub.status.idle":"2022-05-07T15:02:23.474518Z","shell.execute_reply.started":"2022-05-07T15:02:18.98666Z","shell.execute_reply":"2022-05-07T15:02:23.473802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_to_nn = [\n    'name', 'mileage', 'productionDate', 'vehicle', 'modelDateLog', 'model_info', 'name1', 'age', 'epvLog', \n    'edvMinMax', \n    'enginePower', 'engineDisplacement',\n    #'descriptionLen', 'vehicleConfiguration'\n]","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:21:10.812076Z","iopub.execute_input":"2022-05-07T15:21:10.812771Z","iopub.status.idle":"2022-05-07T15:21:10.817862Z","shell.execute_reply.started":"2022-05-07T15:21:10.812735Z","shell.execute_reply":"2022-05-07T15:21:10.817023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tabular\nMake simple neuro net","metadata":{}},{"cell_type":"code","source":"x, y = data.drop([TARGET], axis=1), data[TARGET]/1000000\n\n# x, y = data[list_to_nn], data[TARGET]\n# I try to drop some vectors, whch have small feature impotance. But it didn't improve result\n\n# encode cathegorial data\nencoder=ce.TargetEncoder()\nencoder.fit(x, y)\nx = encoder.transform(x)\n\n# standardize numeric data to best fit for neuro-net\nscaler = StandardScaler().fit(x)\nx = scaler.transform(x)\n\n# split data for train and test parts\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, shuffle=True, random_state=SEED)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T16:50:14.938374Z","iopub.execute_input":"2022-05-15T16:50:14.938625Z","iopub.status.idle":"2022-05-15T16:50:15.459196Z","shell.execute_reply.started":"2022-05-15T16:50:14.938596Z","shell.execute_reply":"2022-05-15T16:50:15.458461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encode and standardized data in test set\nq = test\n#q = test[list_to_nn]   \nq = encoder.transform(q)\nq = scaler.transform(q)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T16:50:21.974077Z","iopub.execute_input":"2022-05-15T16:50:21.974331Z","iopub.status.idle":"2022-05-15T16:50:22.03929Z","shell.execute_reply.started":"2022-05-15T16:50:21.974304Z","shell.execute_reply":"2022-05-15T16:50:22.038566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# my first attempt \nmodel_tab = Sequential()\nmodel_tab.add(L.Dense(2048, input_dim=x_train.shape[1], activation=\"sigmoid\"))\nmodel_tab.add(L.Dropout(0.5))\nmodel_tab.add(L.Dense(1024, activation=\"relu\"))\nmodel_tab.add(L.Dropout(0.5))\nmodel_tab.add(L.Dense(256, activation=\"relu\"))\nmodel_tab.add(L.Dropout(0.25))\nmodel_tab.add(L.Dense(1, activation=\"linear\"))\n# 12.63","metadata":{"execution":{"iopub.status.busy":"2022-05-08T17:44:50.096488Z","iopub.execute_input":"2022-05-08T17:44:50.099031Z","iopub.status.idle":"2022-05-08T17:44:50.148074Z","shell.execute_reply.started":"2022-05-08T17:44:50.098969Z","shell.execute_reply":"2022-05-08T17:44:50.147385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# my second attempt\nmodel_tab = Sequential()\nmodel_tab.add(L.Dense(2048, input_dim=x_train.shape[1], activation=\"relu\"))\nmodel_tab.add(L.Dropout(0.5))\nmodel_tab.add(L.Dense(256, activation=\"relu\"))\nmodel_tab.add(L.Dropout(0.5))\nmodel_tab.add(L.Dense(2048, activation=\"relu\")) \nmodel_tab.add(L.Dropout(0.25))\nmodel_tab.add(L.Dense(256, activation=\"relu\"))  \nmodel_tab.add(L.Dropout(0.25))\nmodel_tab.add(L.Dense(1024, activation=\"relu\"))  \nmodel_tab.add(L.Dropout(0.25))\nmodel_tab.add(L.Dense(256, activation=\"relu\"))  \n#model_tab.add(L.Dropout(0.25))\nmodel_tab.add(L.Dense(1, activation=\"linear\"))\n# 12.47","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:25:47.924329Z","iopub.execute_input":"2022-05-07T17:25:47.925085Z","iopub.status.idle":"2022-05-07T17:25:48.004403Z","shell.execute_reply.started":"2022-05-07T17:25:47.925049Z","shell.execute_reply":"2022-05-07T17:25:48.003599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# My third attempt. I thit it is my best.\nmodel_tab = Sequential()\nmodel_tab.add(L.Dense(256, input_dim=x_train.shape[1], activation=\"sigmoid\"))\nmodel_tab.add(L.BatchNormalization(axis=1))\nmodel_tab.add(L.Dropout(0.5))\nmodel_tab.add(L.Dense(256, activation=\"relu\"))\nmodel_tab.add(L.Dropout(0.5))\nmodel_tab.add(L.Dense(256, activation=\"relu\"))\nmodel_tab.add(L.BatchNormalization(axis=1))\n#model_tab.add(L.Dropout(0.5))\nmodel_tab.add(L.Dense(1, activation=\"linear\"))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T17:52:01.207732Z","iopub.execute_input":"2022-05-08T17:52:01.208291Z","iopub.status.idle":"2022-05-08T17:52:01.278784Z","shell.execute_reply.started":"2022-05-08T17:52:01.20825Z","shell.execute_reply":"2022-05-08T17:52:01.277969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step behind\nAfter experimenting with a tabular and NLP network, I decided to apply the \"feature forwarding\" technique, since we have one feature vector with a very strong correlation with the target vector, and two more with good. So, I add branche with \"linear\" activations and two branches with \"sigmoid\" activations. This is improve results on validation (but not in leaderboard :/...  ).","metadata":{}},{"cell_type":"code","source":"# tab1 \ntab_start = tf.keras.Input(shape=x_train.shape[1])\n\n# main flow of nn-process\ntab_flow1 = Sequential()\ntab_flow1.add(L.Dense(256, activation=\"sigmoid\"))\ntab_flow1.add(L.BatchNormalization(axis=1))\ntab_flow1.add(L.Dropout(0.5))\ntab_flow1.add(L.Dense(256, activation=\"relu\"))\ntab_flow1.add(L.BatchNormalization(axis=1))\ntab_flow1.add(L.Dropout(0.5))\ntab_flow1.add(L.Dense(256, activation=\"relu\"))\ntab_flow1.add(L.BatchNormalization(axis=1))\ntab_flow1.add(L.Dropout(0.25))\ntab_flow1.add(L.Dense(1, activation=\"sigmoid\"))\n\n# main \"forvarding feature\"\ntab_flow2 = L.Dense(1, activation=\"linear\")\n\n# two 'forvarding features with good impotance'\ntab_flow3 = L.Dense(1, activation=\"sigmoid\")\ntab_flow4 = L.Dense(1, activation=\"sigmoid\")\n\n# folding all flows of data processing\ntab_result = tab_flow1(tab_start) + tab_flow2(tab_start) + tab_flow3(tab_start) + tab_flow4(tab_start)\n\n# making model from folded flows\nmodel_tab = Model(inputs=tab_start, outputs=tab_result, name='Tabular')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:50:50.921379Z","iopub.execute_input":"2022-05-09T06:50:50.921687Z","iopub.status.idle":"2022-05-09T06:50:51.059706Z","shell.execute_reply.started":"2022-05-09T06:50:50.921655Z","shell.execute_reply":"2022-05-09T06:50:51.058988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tab2. \n# It was trying to avoide overfitting. Faild\ntab_start = tf.keras.Input(shape=x_train.shape[1])\n\ntab_flow1 = Sequential()\ntab_flow1.add(L.Dense(512, activation=\"sigmoid\"))\ntab_flow1.add(L.BatchNormalization(axis=1))\ntab_flow1.add(L.Dropout(0.5))\ntab_flow1.add(L.Dense(512, activation=\"relu\"))\ntab_flow1.add(L.BatchNormalization(axis=1))\ntab_flow1.add(L.Dropout(0.5))\ntab_flow1.add(L.Dense(512, activation=\"relu\"))\ntab_flow1.add(L.BatchNormalization(axis=1))\ntab_flow1.add(L.Dropout(0.25))\ntab_flow1.add(L.Dense(1, activation=\"sigmoid\"))\n\ntab_flow2 = L.Dense(1, activation=\"linear\")\n\ntab_flow3 = L.Dense(1, activation=\"sigmoid\")\ntab_flow4 = L.Dense(1, activation=\"sigmoid\")\n\ntab_result = tab_flow1(tab_start) + tab_flow2(tab_start) + tab_flow3(tab_start) + tab_flow4(tab_start)\n\nmodel_tab = Model(inputs=tab_start, outputs=tab_result, name='Tabular')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:39:29.133325Z","iopub.execute_input":"2022-05-09T06:39:29.13359Z","iopub.status.idle":"2022-05-09T06:39:31.552749Z","shell.execute_reply.started":"2022-05-09T06:39:29.133559Z","shell.execute_reply":"2022-05-09T06:39:31.552031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Real forvarding feature","metadata":{}},{"cell_type":"code","source":"data.drop(['price', 'description'], axis=1).info()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T13:27:33.317104Z","iopub.execute_input":"2022-05-15T13:27:33.317517Z","iopub.status.idle":"2022-05-15T13:27:33.323497Z","shell.execute_reply.started":"2022-05-15T13:27:33.317479Z","shell.execute_reply":"2022-05-15T13:27:33.321748Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ind_best = 9  # vector 'name'\nind_1 = 6     # vector 'mileage'\nind_2 = 11    # vcnor\n\n# tab1 \n# forwarding exect features\n\ntab_start = tf.keras.Input(shape=x_train.shape[1])\n\n# main flow of nn-process\ntab_flow1 = Sequential()\ntab_flow1.add(L.Dense(256, activation=\"sigmoid\"))\ntab_flow1.add(L.BatchNormalization(axis=1))\ntab_flow1.add(L.Dropout(0.5))\ntab_flow1.add(L.Dense(256, activation=\"relu\"))\ntab_flow1.add(L.BatchNormalization(axis=1))\ntab_flow1.add(L.Dropout(0.5))\ntab_flow1.add(L.Dense(256, activation=\"relu\"))\ntab_flow1.add(L.BatchNormalization(axis=1))\ntab_flow1.add(L.Dropout(0.25))\ntab_flow1.add(L.Dense(1, activation=\"sigmoid\"))\n\n# main \"forvarding feature\"\ntab_flow2 = tf.gather(tab_start, indices = [ind_best], axis=1)\ntab_flow2 = L.Embedding(2,20)\ntab_flow2 = L.Dense(1, activation=\"linear\")\n\n# two 'forvarding features with good impotance'\n#tab_flow3 = tf.gather(tab_start, indices = [ind_1], axis=1)\n#tab_flow3 = L.Embedding(2,20)\n#tab_flow3 = L.Dense(1, activation=\"sigmoid\")\n\n#tab_flow4 = tf.gather(tab_start, indices = [ind_2], axis=1)\n#tab_flow4 = L.Embedding(2,20)\n#tab_flow4 = L.Dense(1, activation=\"sigmoid\")\n\n# folding all flows of data processing\ntab_result = tab_flow1(tab_start) + tab_flow2(tab_start)# + tab_flow3(tab_start) + tab_flow4(tab_start)\n\n# making model from folded flows\nmodel_tab = Model(inputs=tab_start, outputs=tab_result, name='Tabular')\n\n\"\"\"\nВ итоге данная концигурация проброса признака не принесла существенных улучшений в метрике.\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-05-15T17:05:44.489449Z","iopub.execute_input":"2022-05-15T17:05:44.489731Z","iopub.status.idle":"2022-05-15T17:05:44.607911Z","shell.execute_reply.started":"2022-05-15T17:05:44.489672Z","shell.execute_reply":"2022-05-15T17:05:44.607206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_tab.load_weights('../input/tab1hdf5/tab1.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:50:55.768134Z","iopub.execute_input":"2022-05-09T06:50:55.76838Z","iopub.status.idle":"2022-05-09T06:50:55.812743Z","shell.execute_reply.started":"2022-05-09T06:50:55.768352Z","shell.execute_reply":"2022-05-09T06:50:55.812095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_tab.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T16:51:45.452472Z","iopub.execute_input":"2022-05-15T16:51:45.453078Z","iopub.status.idle":"2022-05-15T16:51:45.466424Z","shell.execute_reply.started":"2022-05-15T16:51:45.453034Z","shell.execute_reply":"2022-05-15T16:51:45.465626Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile model\noptimizer = tf.keras.optimizers.Adam(0.01)\nmodel_tab.compile(loss='MAPE',optimizer=optimizer, metrics=['MAPE'])","metadata":{"execution":{"iopub.status.busy":"2022-05-15T17:06:06.412074Z","iopub.execute_input":"2022-05-15T17:06:06.412334Z","iopub.status.idle":"2022-05-15T17:06:06.424605Z","shell.execute_reply.started":"2022-05-15T17:06:06.412305Z","shell.execute_reply":"2022-05-15T17:06:06.423911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint('../working/best_model.hdf5' , monitor=['val_MAPE'], verbose=0  , mode='min')\nearlystop = EarlyStopping(monitor='val_MAPE', patience=100, restore_best_weights=True,)\ncallbacks_list = [checkpoint, earlystop]","metadata":{"execution":{"iopub.status.busy":"2022-05-15T17:06:08.170522Z","iopub.execute_input":"2022-05-15T17:06:08.170782Z","iopub.status.idle":"2022-05-15T17:06:08.17519Z","shell.execute_reply.started":"2022-05-15T17:06:08.170752Z","shell.execute_reply":"2022-05-15T17:06:08.174286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_tab = model_tab.fit(x_train, y_train,\n                    batch_size=128,\n                    epochs=1000,                       # to the fact, we wil wait early stop\n                    validation_data=(x_test, y_test),\n                    callbacks=callbacks_list,\n                    verbose=0,\n                   )","metadata":{"execution":{"iopub.status.busy":"2022-05-15T17:14:07.974209Z","iopub.execute_input":"2022-05-15T17:14:07.974461Z","iopub.status.idle":"2022-05-15T17:14:56.240722Z","shell.execute_reply.started":"2022-05-15T17:14:07.974431Z","shell.execute_reply":"2022-05-15T17:14:56.239982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Loss')\nplt.plot(history_tab.history['MAPE'], label='train')\nplt.plot(history_tab.history['val_MAPE'], label='test')\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2022-05-15T17:15:30.115246Z","iopub.execute_input":"2022-05-15T17:15:30.115506Z","iopub.status.idle":"2022-05-15T17:16:30.098491Z","shell.execute_reply.started":"2022-05-15T17:15:30.115477Z","shell.execute_reply":"2022-05-15T17:16:30.097781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_tab.load_weights('../working/best_model.hdf5')\nmodel_tab.save('../working/tab1_ff2.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T17:05:17.71847Z","iopub.execute_input":"2022-05-15T17:05:17.718755Z","iopub.status.idle":"2022-05-15T17:05:17.801635Z","shell.execute_reply.started":"2022-05-15T17:05:17.718718Z","shell.execute_reply":"2022-05-15T17:05:17.800915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tab_prediction = model_tab.predict(x_test)\n\nprint(f\"TEST mape: {(mape(y_test, tab_prediction[:,0])):0.2f}%\")\n# 12.47","metadata":{"execution":{"iopub.status.busy":"2022-05-15T17:16:34.896824Z","iopub.execute_input":"2022-05-15T17:16:34.897477Z","iopub.status.idle":"2022-05-15T17:16:34.973582Z","shell.execute_reply.started":"2022-05-15T17:16:34.897439Z","shell.execute_reply":"2022-05-15T17:16:34.972852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tab_predict = model_tab.predict(q)*1000000\ntest['price'] = tab_predict[:,0]","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:54:35.451799Z","iopub.execute_input":"2022-05-09T06:54:35.452097Z","iopub.status.idle":"2022-05-09T06:54:35.553714Z","shell.execute_reply.started":"2022-05-09T06:54:35.452068Z","shell.execute_reply":"2022-05-09T06:54:35.552998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nn1_prediction = test[['sell_id', 'price']]\nnn1_prediction.to_csv('tab_sub2.csv', index=False)\nnn1_prediction\n# 12.45 best on leaderboard","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:54:55.101558Z","iopub.execute_input":"2022-05-09T06:54:55.101831Z","iopub.status.idle":"2022-05-09T06:54:55.132661Z","shell.execute_reply.started":"2022-05-09T06:54:55.101798Z","shell.execute_reply":"2022-05-09T06:54:55.131782Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I see there are several problems, which I didnt solve\n* overfitting\n* not clear data\n\nTo avoide overfitting I used Batch- and Drop-out-normalization, chose bigger batch-size. But after several attempts, MAPE of process data being better, instead of validation MAPE.\n","metadata":{}},{"cell_type":"markdown","source":"## Tabular & NLP\n* double input neuronet \n* clear text","metadata":{}},{"cell_type":"code","source":"!pip install pymorphy2\nimport pymorphy2","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:55:45.500307Z","iopub.execute_input":"2022-05-09T06:55:45.500568Z","iopub.status.idle":"2022-05-09T06:56:00.457934Z","shell.execute_reply.started":"2022-05-09T06:55:45.500539Z","shell.execute_reply":"2022-05-09T06:56:00.457143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clear text from english words, nombers and symbols and normalize form of word \nmorph = pymorphy2.MorphAnalyzer()\n\npatterns = \"[A-Za-z0-9!#$%&'()*+,./:;<=>?@[\\]^_`{|}~—\\\"\\-]+\"\n\ndef lemmatize(doc):\n    doc = re.sub(patterns, ' ', doc)          # data clearance \n    tokens = []\n    for token in doc.split():\n        token = token.strip()\n        token = morph.normal_forms(token)[0]  # normalize form of word \n        tokens.append(token)\n    return ' '.join(tokens)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:56:00.459853Z","iopub.execute_input":"2022-05-09T06:56:00.460124Z","iopub.status.idle":"2022-05-09T06:56:00.930184Z","shell.execute_reply.started":"2022-05-09T06:56:00.460085Z","shell.execute_reply":"2022-05-09T06:56:00.92949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cooking()\ndata_lem = data.append(test).copy() # concatenate data and train to make clearance","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:56:24.487382Z","iopub.execute_input":"2022-05-09T06:56:24.488109Z","iopub.status.idle":"2022-05-09T06:56:25.373157Z","shell.execute_reply.started":"2022-05-09T06:56:24.488071Z","shell.execute_reply":"2022-05-09T06:56:25.372385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_lem['description'] = data_lem.description.apply(lemmatize)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:56:26.775203Z","iopub.execute_input":"2022-05-09T06:56:26.775463Z","iopub.status.idle":"2022-05-09T07:01:22.843645Z","shell.execute_reply.started":"2022-05-09T06:56:26.775432Z","shell.execute_reply":"2022-05-09T07:01:22.842947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# separate to data and test again after clearance\ntest_lem=data_lem[pd.isna(data_lem.price)]\ndata_lem=data_lem[data_lem.price >0]\ntest_lem.drop([TARGET], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T07:02:06.660589Z","iopub.execute_input":"2022-05-09T07:02:06.660874Z","iopub.status.idle":"2022-05-09T07:02:06.674788Z","shell.execute_reply.started":"2022-05-09T07:02:06.660826Z","shell.execute_reply":"2022-05-09T07:02:06.673858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_to_drop_nn = ['engineDisplacementValue','modelDate','modelDateMM','Руль','enginePowerValue']\n\ndata = data_lem.drop(list_to_drop_nn, axis=1) #lem\ntest = test_lem.drop(list_to_drop_nn, axis=1) #lem\n\n\n# split and processing data for NN models\n# we need same splitting for NLP-model and tabular-model\n# but all pre-processing (encoding and standard scaling) need to make on all data-set\nx, y, q = data.drop(TARGET, axis=1), data[TARGET], test\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, shuffle=True, random_state=SEED)\n\ntext_train = x_train.description\ntext_test = x_test.description\ntext_sub = test.description\n\nx, q = x.drop('description', axis=1), q.drop('description', axis=1)\nx_train = x_train.drop('description', axis=1)\nx_test = x_test.drop('description', axis=1)\n\nencoder=ce.TargetEncoder().fit(x,y)\nx, q = encoder.transform(x), encoder.transform(q)\nx_train, x_test = encoder.transform(x_train), encoder.transform(x_test)\n\nscaler = StandardScaler().fit(x)\nx_train, x_test, q = scaler.transform(x_train), scaler.transform(x_test), scaler.transform(q)\nx = scaler.transform(x)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T07:02:14.396034Z","iopub.execute_input":"2022-05-09T07:02:14.396412Z","iopub.status.idle":"2022-05-09T07:02:14.999383Z","shell.execute_reply.started":"2022-05-09T07:02:14.396363Z","shell.execute_reply":"2022-05-09T07:02:14.998658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TOKENIZER\nMAX_WORDS = 100000          # The maximum number of words to be used. (most frequent)\nMAX_SEQUENCE_LENGTH = 256   # Max number of words in each complaint.","metadata":{"execution":{"iopub.status.busy":"2022-05-09T07:02:20.33325Z","iopub.execute_input":"2022-05-09T07:02:20.334013Z","iopub.status.idle":"2022-05-09T07:02:20.338606Z","shell.execute_reply.started":"2022-05-09T07:02:20.333969Z","shell.execute_reply":"2022-05-09T07:02:20.337803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntokenize = Tokenizer(num_words=MAX_WORDS)\ntokenize.fit_on_texts(data.description)\ntokenize.word_index","metadata":{"execution":{"iopub.status.busy":"2022-05-09T07:02:21.205609Z","iopub.execute_input":"2022-05-09T07:02:21.206447Z","iopub.status.idle":"2022-05-09T07:02:22.182367Z","shell.execute_reply.started":"2022-05-09T07:02:21.2064Z","shell.execute_reply":"2022-05-09T07:02:22.181672Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntext_train_sequences = sequence.pad_sequences(tokenize.texts_to_sequences(text_train), maxlen=MAX_SEQUENCE_LENGTH)\ntext_test_sequences = sequence.pad_sequences(tokenize.texts_to_sequences(text_test), maxlen=MAX_SEQUENCE_LENGTH)\ntext_sub_sequences = sequence.pad_sequences(tokenize.texts_to_sequences(text_sub), maxlen=MAX_SEQUENCE_LENGTH)\n\nprint(text_train_sequences.shape, text_test_sequences.shape, text_sub_sequences.shape, )","metadata":{"execution":{"iopub.status.busy":"2022-05-09T07:02:30.332513Z","iopub.execute_input":"2022-05-09T07:02:30.332764Z","iopub.status.idle":"2022-05-09T07:02:31.451806Z","shell.execute_reply.started":"2022-05-09T07:02:30.332734Z","shell.execute_reply":"2022-05-09T07:02:31.451074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_tab = Sequential()\n#model_tab.add(L.Dense(2048, input_dim=x_train.shape[1], activation=\"sigmoid\"))\n#model_tab.add(L.Dropout(0.5))\n#model_tab.add(L.Dense(1024, activation=\"relu\"))\n#model_tab.add(L.Dropout(0.5))\n#model_tab.add(L.Dense(256, activation=\"relu\"))\n#odel_tab.add(L.Dropout(0.25))\n#model_tab.add(L.Dense(1, activation=\"linear\"))\n#12.63","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:01:43.99643Z","iopub.execute_input":"2022-05-08T08:01:43.997115Z","iopub.status.idle":"2022-05-08T08:01:46.547488Z","shell.execute_reply.started":"2022-05-08T08:01:43.997078Z","shell.execute_reply":"2022-05-08T08:01:46.546782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_tab = Sequential()\n#model_tab.add(L.Dense(2048, input_dim=x_train.shape[1], activation=\"relu\"))\n#model_tab.add(L.Dropout(0.5))\n#model_tab.add(L.Dense(256, activation=\"relu\"))\n#model_tab.add(L.Dropout(0.5))\n#odel_tab.add(L.Dense(2048, activation=\"relu\")) \n#model_tab.add(L.Dropout(0.25))\n#odel_tab.add(L.Dense(256, activation=\"relu\"))  \n#odel_tab.add(L.Dropout(0.25))\n#model_tab.add(L.Dense(1024, activation=\"relu\"))  \n#model_tab.add(L.Dropout(0.25))\n#model_tab.add(L.Dense(256, activation=\"relu\"))  \n#model_tab.add(L.Dropout(0.25))\n#model_tab.add(L.Dense(1, activation=\"linear\"))\n# 12.47","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:45:10.163998Z","iopub.execute_input":"2022-05-07T16:45:10.164803Z","iopub.status.idle":"2022-05-07T16:45:10.23346Z","shell.execute_reply.started":"2022-05-07T16:45:10.16476Z","shell.execute_reply":"2022-05-07T16:45:10.232791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tab1 , without top\ntab_start = tf.keras.Input(shape=x_train.shape[1])\n\ntab_flow1 = Sequential()\ntab_flow1.add(L.Dense(256, activation=\"sigmoid\"))\ntab_flow1.add(L.BatchNormalization(axis=1))\ntab_flow1.add(L.Dropout(0.5))\ntab_flow1.add(L.Dense(256, activation=\"relu\"))\ntab_flow1.add(L.BatchNormalization(axis=1))\ntab_flow1.add(L.Dropout(0.5))\ntab_flow1.add(L.Dense(256, activation=\"relu\"))\ntab_flow1.add(L.BatchNormalization(axis=1))\ntab_flow1.add(L.Dropout(0.25))\n#tab_flow1.add(L.Dense(1, activation=\"sigmoid\"))\n\ntab_flow2 = L.Dense(1, activation=\"linear\")\n\ntab_flow3 = L.Dense(1, activation=\"sigmoid\")\ntab_flow4 = L.Dense(1, activation=\"sigmoid\")\n\ntab_result = tab_flow1(tab_start) + tab_flow2(tab_start) + tab_flow3(tab_start) + tab_flow4(tab_start)\n\nmodel_tab = Model(inputs=tab_start, outputs=tab_result, name='Tabular')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-09T07:46:33.940902Z","iopub.execute_input":"2022-05-09T07:46:33.94148Z","iopub.status.idle":"2022-05-09T07:46:34.063908Z","shell.execute_reply.started":"2022-05-09T07:46:33.94144Z","shell.execute_reply":"2022-05-09T07:46:34.063173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_nlp = Sequential()\nmodel_nlp.add(L.Input(shape=MAX_SEQUENCE_LENGTH, name=\"seq_description\"))\nmodel_nlp.add(L.Embedding(len(tokenize.word_index)+1, MAX_SEQUENCE_LENGTH,))\nmodel_nlp.add(L.LSTM(256, return_sequences=True))\nmodel_nlp.add(L.Dropout(0.5))\nmodel_nlp.add(L.Dense(128, activation=\"sigmoid\"))\nmodel_nlp.add(L.Dropout(0.5))\nmodel_nlp.add(L.LSTM(128,))\nmodel_nlp.add(L.Dropout(0.25))\nmodel_nlp.add(L.Dense(64, activation=\"relu\"))\nmodel_nlp.add(L.Dropout(0.25))","metadata":{"execution":{"iopub.status.busy":"2022-05-09T07:47:09.266881Z","iopub.execute_input":"2022-05-09T07:47:09.267426Z","iopub.status.idle":"2022-05-09T07:47:09.724862Z","shell.execute_reply.started":"2022-05-09T07:47:09.267386Z","shell.execute_reply":"2022-05-09T07:47:09.724153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doubleInput = L.concatenate([model_nlp.output, model_tab.output])\nfunnel = L.Dense(64, activation=\"relu\")(doubleInput)\nfunnel = L.Dense(1, activation=\"linear\")(funnel)\n\nmodel = Model(inputs=[model_nlp.input, model_tab.input], outputs=funnel)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T07:47:10.308685Z","iopub.execute_input":"2022-05-09T07:47:10.309222Z","iopub.status.idle":"2022-05-09T07:47:10.335383Z","shell.execute_reply.started":"2022-05-09T07:47:10.309184Z","shell.execute_reply":"2022-05-09T07:47:10.334743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T07:47:13.52526Z","iopub.execute_input":"2022-05-09T07:47:13.526048Z","iopub.status.idle":"2022-05-09T07:47:13.543924Z","shell.execute_reply.started":"2022-05-09T07:47:13.526009Z","shell.execute_reply":"2022-05-09T07:47:13.543239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(0.01)\nmodel.compile(loss='MAPE',optimizer=optimizer, metrics=['MAPE'])\ncheckpoint = ModelCheckpoint('../working/best_model.hdf5', monitor=['val_MAPE'], verbose=0, mode='min')\nearlystop = EarlyStopping(monitor='val_MAPE', patience=90, restore_best_weights=True,)\ncallbacks_list = [checkpoint, earlystop]","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:10:41.810152Z","iopub.execute_input":"2022-05-09T08:10:41.81041Z","iopub.status.idle":"2022-05-09T08:10:41.823181Z","shell.execute_reply.started":"2022-05-09T08:10:41.81038Z","shell.execute_reply":"2022-05-09T08:10:41.822232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.load_weights('../input/nn-tab-nlp/nn_mlp_nlp (1).hdf5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_multy = model.fit([text_train_sequences, x_train], y_train,\n                    batch_size=256,\n                    epochs=500, # фактически мы обучаем пока EarlyStopping не остановит обучение\n                    validation_data=([text_test_sequences, x_test], y_test),\n                    callbacks=callbacks_list\n                   )","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:58:21.746769Z","iopub.execute_input":"2022-05-09T08:58:21.747044Z","iopub.status.idle":"2022-05-09T09:05:19.885004Z","shell.execute_reply.started":"2022-05-09T08:58:21.747014Z","shell.execute_reply":"2022-05-09T09:05:19.884215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Loss')\nplt.plot(history_multy.history['MAPE'], label='train')\nplt.plot(history_multy.history['val_MAPE'], label='test')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T09:05:25.03594Z","iopub.execute_input":"2022-05-09T09:05:25.036501Z","iopub.status.idle":"2022-05-09T09:05:43.860369Z","shell.execute_reply.started":"2022-05-09T09:05:25.03646Z","shell.execute_reply":"2022-05-09T09:05:43.859695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('../working/best_model.hdf5')\nmodel.save('../working/nn2_nlp_tab.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-05-09T09:05:49.228587Z","iopub.execute_input":"2022-05-09T09:05:49.228854Z","iopub.status.idle":"2022-05-09T09:05:49.475647Z","shell.execute_reply.started":"2022-05-09T09:05:49.228809Z","shell.execute_reply":"2022-05-09T09:05:49.474804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.load_weights('../input/nn-tab-nlp/nn_mlp_nlp (1).hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-05-09T09:05:50.495959Z","iopub.execute_input":"2022-05-09T09:05:50.496618Z","iopub.status.idle":"2022-05-09T09:05:50.500181Z","shell.execute_reply.started":"2022-05-09T09:05:50.49658Z","shell.execute_reply":"2022-05-09T09:05:50.49937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predict_nn2 = model.predict([text_test_sequences, x_test])\nprint(f\"TEST mape: {(mape(y_test, test_predict_nn2[:,0])):0.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2022-05-09T09:05:51.796204Z","iopub.execute_input":"2022-05-09T09:05:51.796576Z","iopub.status.idle":"2022-05-09T09:05:52.241481Z","shell.execute_reply.started":"2022-05-09T09:05:51.796543Z","shell.execute_reply":"2022-05-09T09:05:52.240615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_predict_nn2 = model.predict([text_sub_sequences, q])\ntest['price'] = sub_predict_nn2[:,0]\n\nnn2_prediction = test[['sell_id', 'price']]\nnn2_prediction.to_csv('nn2_sub.csv', index=False)\nnn2_prediction\n#13.99 (first attempt)\n#13.88 (list to drop)\n#12.12 (Tabular2 + NLP)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:35:34.300402Z","iopub.execute_input":"2022-05-09T08:35:34.300655Z","iopub.status.idle":"2022-05-09T08:35:34.98545Z","shell.execute_reply.started":"2022-05-09T08:35:34.300626Z","shell.execute_reply":"2022-05-09T08:35:34.984737Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resume\n\nDoubleInput improve MAPE only a little, and it is still worse of Catboost ML-model. \n\nOnly one way to go better is to work more on text in vector description. ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}