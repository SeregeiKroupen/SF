# Отчет по проекту "Возьмете Бэт-мобиль?"  
----

Работа оформлена в виде трех ноутбуков:   
1) **MultyInput_CarPricesPrediction_EDA.ipynb**:  
   * решена задача EDA и FE по сырым данным  
2) **multyinput-carpricesprediction-nn-v0-ipynb.ipynb**: 
   * решена задача использования нейросетей для предсказания по табличным данным  
   * и по текстовой информации из вектора "описание" ('description')   

3) **multyinput-carpricesprediction-final-v0-ipynb.ipynb**:  
   * решена задача использования изображений для предсказания в составе многовходовой нейросети  
   * использован прием "смешивания" результатов работы ML и DL решений.  

# Этап 1. EDA и FE
Наивная MLмодель показала МАРЕ=12.5% (наилучший результат) у Catboost Regr. Были испробованы несколько других моделей, из кроторых наиболее близкий результат к наилучшему показал RandomForest Regr.
На первом этапе произведен анализ данных в таблице, очистка, и генерация новых признаков.

На мой взгляд, наилучший результат из генерации признаков получен от вектора "Наименование"
('name'), у него самая лучшая "значимость" по модели Catboost.

Также есть видимые улучшения метрики от выделения цифровых данных из текстовой формы записи данных в векторах, а также некоторая манипуляция с ними (мини-макс нормализация, логарифмирование)  

Применил очистку данных, которые не встречаются в тренировочной базе, не встречаются в тестовой. Считаю это "шумом", который не сможет помочь в работе регрессора. По итогу исключения были отмечены улучшения метрики.  

По итогу работы написал функцию, производящую манипуляции с данными в датасетах от самой загрузки из источников, проверенно улучшающими результат, чтобы использовать ее в последующей работе в на других этапах.  

Далее, провел анализ кросскореляции признаков и исключил в финале несколько векторов из работы, что позволило поднять результат еще на несколько сотых пунктов.  

Результат на соревновании составил 11.6153%

Далее я провел эксперимент по проверке гипотезы. Основная идея в том, чтобы до работы регрессора провести классификацию записей алгоритмом классификации.  
1. На первом этапе я в ручную разделил данные по бренду автомобиля и применил регрессор внутри брендов для предсказания соответствующих результатов в тестовой выборке.   
2. На втором этапе включался алгоримт KMeans. По предсказанным кластерам производилось обучение регрессора отдельно и осуществлялось предсказание каждой записи в тесте. Итоговое предсказание я делал двумя способами.
   1. Брал среднеевзвешенное значение по предсказаниям, где весами были вероятности отнесения этого авто к расчитанному классу.
   2. Брал предсказание строго от того регрессора, который натренирован по классу именно этого авто.  

К сожалению, улучшить метрику мне не удалось. Но все равно считаю этот подход перспективным. Нужно просто время и аналитическая база для успешного применеия.  

# Этап 2. Нейросети для табличных данны и для анализа текстовой информации.

### Первая часть - применение DL для табличных данных датасета.
Эксперименты с дизайном нейросетей привели к очень прсотой по сути с малым 
количеством нейронов в каждом слое сети.  

Далее, я реализовал методику "проброса признака". Первоначально, идея была в том, 
что у нас есть один очень сильный признак, который можно использовать непосредственно
в результате ("наименование" - 'name'), а также - два признака с хорошим уровнем 
важности (все по результатам работы Catboost regressoor). 
Первый признак я активировал линейно, остальные - с сигмоидой. В результате, получилось 
сделать лучшее из всех вариантов, предсказание. Однако, хуже результата ML. 

Надо отметить, что первоначально я использовал простую схему, без выбора внутри сети 
конкретного вектора для проброса, а только делал "червоточину".  
В последствии, я попробовал схему с выбором конкретного вектора в датасете для проброса. 
Однако, результат по метрике оказался не лучше, чем был при использовании "простой" 
схемы.  

В дальнейшем я продолжил использовать именно этот "простой" дизайн табличной нейросети 
в сложной сети с несколькими входами.

### Вторая часть - применение DL для анализа текстовой информации из вектора "описание" ('decription')  

Работа проделана только в части лематизации и очистке данных в объявлениях от знаков, 
то есть, применен стандартный механизм работы с текстом.  

В результате, совместный дизайн сети по анализу табличной информации и текстовой 
информации из поля "описание", манипуляции с набором векторов, дало только 
незначительное улучшение метрики МАРЕ, все же, однако, хуже результата MLмодели. 

Уже на этом этапе очень сильно оказывало влияние факт отстуствия вычислительных 
мощностей. но об этом ниже.'  

# Этап 3. Включение в дизайн модели для анализа фото  

### Построение мульти-входовой модели
Реализована стандатная схема из примера. Сложность оказалась в отсутствии 
вычислительных мощностей всю эту модель натренировать. 30 часов Каггл кончились 
моментально, а Колаб на неделе по два-три дня не пускал на GPU. 
Учитывая, что загрузка данных в колаб из Каггл почему-то не работала, приходилось
загружать их вручную, также файл с весами модели также надо было отдельно загружать
все это занимало время по 1 часу, прежде чем можно было приступать к продолженю 
работы тогда, когда GPU работало. Само обучение 15-20 эпох занимало от 2 до 5 часов. 
За такой промежуток времени не однократно случались сбои, которые унчтожали результаты 
проделанной работы и приходилось заново загружать файлы данных и весов.  

Таким образом, было крайне затруднительно начинать реально разные эксперименты 
например, по аугментации фото (единственно что я сделал, обнаружил и исправил методы,
которые оказалось работали в Каггл, но не работали в Колабе, и наоборот, хотя это одни 
и те же алгоритмы). Также, не представлялось возможным сильно экспериментировать с
дизайном модели - хоть бы хватило сил провести больше эпох тренировки одного дизайна. 
Ведь, чтобы понять, получилось ли улучшить результат в каком-нибудь эксперименте,
необходимо потратить часов 10 минимум.  

По этой же причине в файле есть блок кода для работы по "тонкой настроке" внешней 
предобученной сети, но в реальности, я этим экспериментом пожертвовал. Так как на 
предыдущем проекте, применяя этот метод, не добился существенного улучшения результата
и сейчас не захотел тратить время работы площадок, оказавшееся таким ценным.

### Смешивание результатов моделирования
Спустя более недели работы по тренировке сети удалось дойти до этапа "смешивания" результатов
работы ML и DL моделей. Я очень хотел попробовать этот метод изначально, но надежды, что 
получится интересный результат не было, учитывая практически все предыдущие результаты, 
кроме Catboosting.  

Однако, именно тут получилось достигнуть лучшей  метрики МАРЕ, чем была у MLмодели.  

С начала, я испольщовал среднеарифметическое действие для порлучнеия результата, но 
позже выяснилось, что пропорция 70 на 30 дает еще лучший результат.  

В итоге на соревновании МАРЕ у меня получился 11.37% (55 место в общем зачете на 15 
мая 2022 года).

# Оценка
Не все удалось реализовать из предложенного плана работы. Однако, я доволен, что попробовал 
развить идею категориальной регрессии, соединив ее с предварительной классификации. С учетом
свободного времени, я планирую развить тему.  
Также мне понравилось работать с нейросетями уже на продвинутом уровне, которым считаю 
методику проброса признака и проектировании дизайна с несколькими входами. Жаль, что 
не хватило ресурсов провести больше экспериментов.  

Таким образом, я доволен и проделанной работой и, что не мало важно, - результатами на соревновании.